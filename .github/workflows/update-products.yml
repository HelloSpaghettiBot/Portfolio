---
name: "Update Gumroad Products (Resilient)"

on:
  schedule:
    - cron: "0 2 * * *"   # daily at 2 AM UTC
  workflow_dispatch:

jobs:
  update:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Fetch all Gumroad products (resilient)
        env:
          GUMROAD_ACCESS_TOKEN: ${{ secrets.GUMROAD_ACCESS_TOKEN }}
        run: |
          python - <<'PY'
          import os, json, time, sys, random
          from urllib import request, parse, error

          TOKEN = os.environ.get("GUMROAD_ACCESS_TOKEN")
          if not TOKEN:
              print("ERROR: Missing GUMROAD_ACCESS_TOKEN", file=sys.stderr)
              sys.exit(1)

          BASE = "https://api.gumroad.com/v2/products"
          UA   = "DigitalOutletSync/1.0 (+https://kozathrift.com)"

          def http_get(url, max_attempts=8, base_delay=1.4, timeout=40):
              """GET with backoff + jitter, retrying 504/5xx/429."""
              last_err = None
              for i in range(max_attempts):
                  req = request.Request(url, headers={"User-Agent": UA, "Accept": "application/json"})
                  try:
                      with request.urlopen(req, timeout=timeout) as r:
                          return json.loads(r.read().decode("utf-8"))
                  except error.HTTPError as e:
                      if e.code in (429, 500, 502, 503, 504):
                          delay = base_delay * (2 ** i) + random.uniform(0, 0.75)
                          print(f"[WARN] HTTP {e.code}, retry {i+1}/{max_attempts} in {delay:.1f}s")
                          time.sleep(delay)
                          last_err = e
                          continue
                      raise
                  except Exception as e:
                      delay = base_delay * (2 ** i) + random.uniform(0, 0.75)
                      print(f"[WARN] {type(e).__name__}: {e}, retry {i+1}/{max_attempts} in {delay:.1f}s")
                      time.sleep(delay)
                      last_err = e
                      continue
              print("[ERROR] Exhausted retries", file=sys.stderr)
              if last_err:
                  raise last_err
              raise RuntimeError("Unknown HTTP failure")

          all_items, seen_ids = [], set()
          page, HARD_CAP = 1, 200
          while page <= HARD_CAP:
              params = {"access_token": TOKEN, "page": page, "per_page": 100}
              url = BASE + "?" + parse.urlencode(params)
              data = http_get(url)
              if not data.get("success"):
                  print(f"[WARN] success=false on page {page}")
                  break

              chunk = data.get("products") or []
              if not chunk:
                  print(f"Page {page}: empty -> stop")
                  break

              new = [p for p in chunk if p.get("id") not in seen_ids]
              for p in new:
                  seen_ids.add(p["id"])
                  all_items.append(p)
              print(f"Page {page}: {len(chunk)} items, {len(new)} new, total {len(all_items)}")

              if not new or data.get("has_more") is False:
                  break
              page += 1
              time.sleep(0.25)

          # Normalize (multi-image candidates for robust rendering)
          out = []
          for p in all_items:
              title = p.get("name") or "Untitled"
              url   = p.get("short_url") or p.get("url") or ""
              imgs  = []
              for k in ("preview_url", "cover_image_url", "thumbnail_url"):
                  v = p.get(k)
                  if v and v not in imgs:
                      imgs.append(v)
              if not imgs:
                  seed = parse.quote(title)
                  imgs.append(f"https://picsum.photos/seed/{seed}/800/800")
              out.append({"title": title, "url": url, "images": imgs})

          # Deduplicate
          seen, dedup = set(), []
          for item in out:
              key = (item["url"], item["title"])
              if key in seen:
                  continue
              seen.add(key)
              dedup.append(item)

          with open("products.json", "w", encoding="utf-8") as f:
              json.dump(dedup, f, indent=2, ensure_ascii=False)

          print(f"âœ… Saved {len(dedup)} products to products.json")
          PY

      - name: Commit & push products.json
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add products.json
          git commit -m "Auto-update Gumroad products" || echo "No changes"
          git push
